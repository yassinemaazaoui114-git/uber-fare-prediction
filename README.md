# ğŸš• Uber Fare Prediction System

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://python.org)
[![GitHub](https://img.shields.io/badge/GitHub-Repository-181717.svg)](https://github.com/yassinemaazaoui114-git/uber-fare-prediction)
[![License](https://img.shields.io/badge/License-Educational-green.svg)]()

> **Note:** Model files (`.joblib`) are excluded from this repository due to size constraints. 
> Run `make train` after setup to generate models locally.

---

## ğŸš€ Quick Start

Clone the repository
git clone https://github.com/yassinemaazaoui114-git/uber-fare-prediction.git
cd uber-fare-prediction

Setup environment (creates venv and installs dependencies)
make setup

Activate virtual environment
source venv/bin/activate # Linux/Mac

OR
venv\Scripts\activate # Windows

Train models (~3 minutes)
make train

Run tests
make test

[Rest of your existing README content...]

Then commit:

git add README.md
git commit -m "Add installation instructions and badges to README"
git push

A production-ready machine learning system for predicting Uber ride fares using advanced ensemble methods and automated workflows.

## ğŸ¯ Project Overview

This project implements **9 different machine learning models** to predict Uber fares with **72.6% accuracy**, reducing prediction error to an average of **$1.37 per ride**. The system includes automated training pipelines, comprehensive testing, and professional code quality checks.

### Key Achievements
- âœ… **72.6% RÂ² Score** (CatBoost model)
- âœ… **$1.37 average prediction error**
- âœ… **9 trained models** including advanced ensemble methods
- âœ… **13 engineered features** for optimal performance
- âœ… **100% code quality** with automated CI/CD checks
- âœ… **Zero security vulnerabilities**

---

## ğŸ“Š Model Performance

| Model | RÂ² Score | RMSE | MAE | Status |
|-------|----------|------|-----|--------|
| **CatBoost** â­ | **0.7263** | **$1.93** | **$1.37** | Recommended |
| LightGBM | 0.7171 | $1.96 | $1.41 | Fast & Accurate |
| Stacking Ensemble | 0.7161 | $1.97 | $1.41 | Most Robust |
| Gradient Boosting | 0.6948 | $2.04 | $1.46 | Stable |
| Random Forest | 0.6929 | $2.05 | $1.48 | Interpretable |
| XGBoost | 0.6923 | $2.05 | $1.47 | Industry Standard |
| Linear Regression | 0.6488 | $2.19 | $1.56 | Baseline |
| K-Nearest Neighbors | 0.6341 | $2.23 | $1.60 | Simple |
| Decision Tree | 0.3419 | $2.99 | $2.11 | Not Recommended |

---

## ğŸ—ï¸ Project Structure

uber_fare_prediction/
â”‚
â”œâ”€â”€ Makefile                  # Automated commands
â”œâ”€â”€ main.py                   # Training pipeline with CLI
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ pyproject.toml            # Code formatting configuration
â”œâ”€â”€ .flake8                   # Linting configuration
â”œâ”€â”€ bandit.yml                # Security configuration
â”œâ”€â”€ README.md                 # Project documentation
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ datauber.csv          # Dataset (44,377 rides)
â”‚
â”œâ”€â”€ models/                   # Trained models
â”‚   â”œâ”€â”€ catboost_model.joblib
â”‚   â”œâ”€â”€ lightgbm_model.joblib
â”‚   â”œâ”€â”€ stacking_model.joblib
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ pipelines/                # Model implementations
â”‚   â”œâ”€â”€ catboost_pipeline.py
â”‚   â”œâ”€â”€ lightgbm_pipeline.py
â”‚   â”œâ”€â”€ xgboost_pipeline.py
â”‚   â”œâ”€â”€ stacking_pipeline.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ utils/                    # Utility functions
â”‚   â””â”€â”€ data_loader.py        # Data preprocessing
â”‚
â””â”€â”€ tests/                    # Automated tests
    â””â”€â”€ test_models.py        # Unit tests (6 tests)
---

## ğŸš€ Quick Start

### 1. Setup Environment

Navigate to project
cd uber_fare_prediction

Create and activate virtual environment
make setup

Or manually:
python3 -m venv venv
source venv/bin/activate # On Windows: venv\Scripts\activate
pip install -r requirements.txt


### 2. Train Models

Fast training (~3 minutes)
make train

With hyperparameter tuning (~20 minutes)
make train-tuned

### 3. Run Tests

Run all quality checks
make ci

Individual checks
make test # Run tests
make lint # Check code quality
make format # Auto-format code
make security # Security scan


---

## ğŸ’» Usage Examples

### Command Line Interface

Train all models (fast mode)
python3 main.py

Train with hyperparameter tuning
python3 main.py --tune

Evaluate existing models
python3 main.py --evaluate


### Python API

import joblib
import pandas as pd

Load the best model
model = joblib.load('models/catboost_model.joblib')

Prepare input data
trip_data = pd.DataFrame({
'hour': ,
'day_of_week': ,
'pickup_longitude': [-73.985],
'pickup_latitude': [40.748],
'dropoff_longitude': [-73.974],
'dropoff_latitude': [40.750],
'passenger_count': ,
'trip_km': [2.3],
'is_rush_hour': ,
'is_weekend': ,
'is_late_night': ,
'distance_category': ,
'hour_distance_interaction': [32.2]
})

Make prediction
if isinstance(model, dict): # CatBoost special handling
preprocessor = model['preprocessor']
catboost_model = model['model']
trip_prep = preprocessor.transform(trip_data)
predicted_fare = catboost_model.predict(trip_prep)
else:
predicted_fare = model.predict(trip_data)

print(f"Predicted Fare: ${predicted_fare:.2f}")


---

## ğŸ› ï¸ Available Make Commands

| Command | Description | Time |
|---------|-------------|------|
| `make help` | Show all commands | Instant |
| `make setup` | Create venv and install dependencies | 2 min |
| `make train` | Train all models (fast) | 3 min |
| `make train-tuned` | Train with hyperparameter tuning | 20 min |
| `make test` | Run automated tests | 2 sec |
| `make lint` | Check code quality | 1 sec |
| `make format` | Auto-format code | 1 sec |
| `make security` | Security vulnerability scan | 1 sec |
| `make ci` | Run all quality checks | 5 sec |
| `make clean` | Remove cache files | 1 sec |
| `make clean-models` | Remove saved models | 1 sec |

---

## ğŸ“ˆ Feature Engineering

The system uses **13 engineered features** for optimal predictions:

### Base Features (8)
- `hour` - Hour of pickup (0-23)
- `day_of_week` - Day of week (0=Monday, 6=Sunday)
- `pickup_longitude` - Pickup GPS longitude
- `pickup_latitude` - Pickup GPS latitude
- `dropoff_longitude` - Dropoff GPS longitude
- `dropoff_latitude` - Dropoff GPS latitude
- `passenger_count` - Number of passengers (1-6)
- `trip_km` - Trip distance in kilometers (Haversine formula)

### Enhanced Features (5)
- `is_rush_hour` - Binary flag (7-9am, 5-7pm weekdays)
- `is_weekend` - Binary flag (Saturday/Sunday)
- `is_late_night` - Binary flag (10pm-4am)
- `distance_category` - Trip length category (1=short, 4=very long)
- `hour_distance_interaction` - Interaction term (hour Ã— distance)

---

## ğŸ§ª Testing & Quality Assurance

### Automated Tests

$ make test
âœ… test_models_directory_exists PASSED
âœ… test_data_directory_exists PASSED
âœ… test_catboost_model_file_exists PASSED
âœ… test_lightgbm_model_file_exists PASSED
âœ… test_model_can_load PASSED
âœ… test_prediction_shape PASSED

6 passed in 1.49s


### Code Quality
- âœ… **Linting:** flake8 (0 issues)
- âœ… **Formatting:** Black (100% compliant)
- âœ… **Security:** Bandit (0 vulnerabilities)
- âœ… **Type Safety:** Static analysis ready

---

## ğŸ“¦ Requirements

### Python Version
- Python 3.12+ (tested on 3.12.3)

### Key Dependencies

pandas>=2.1.0
numpy>=1.26.0
scikit-learn>=1.3.0
xgboost
lightgbm
catboost
joblib>=1.3.2
pytest
black
flake8
bandit


---

## ğŸ“ Model Descriptions

### CatBoost (Recommended)
- **Type:** Gradient Boosting on Decision Trees
- **Strengths:** Best accuracy, handles categorical features well, robust to overfitting
- **Use Case:** Production deployment, highest accuracy needed

### LightGBM
- **Type:** Gradient Boosting Machine
- **Strengths:** Fastest training, efficient memory usage, great accuracy
- **Use Case:** Real-time predictions, large datasets

### Stacking Ensemble
- **Type:** Meta-learning ensemble (combines LightGBM, Gradient Boosting, Random Forest)
- **Strengths:** Most robust, averages out individual model weaknesses
- **Use Case:** When reliability is critical, ensemble predictions

---

## ğŸ”¬ Methodology

### Data Preprocessing
1. **Data Cleaning:** Remove duplicates, handle missing values
2. **Outlier Removal:** IQR method (Q1 - 1.5Ã—IQR, Q3 + 1.5Ã—IQR)
3. **Feature Engineering:** Create time-based and interaction features
4. **Train/Test Split:** 80% training, 20% testing (random_state=42)
5. **Standardization:** StandardScaler for all numeric features

### Model Training
1. **Individual Models:** Train 8 different algorithms
2. **Hyperparameter Tuning:** RandomizedSearchCV with 5-fold CV (optional)
3. **Stacking:** Combine top 3 models with Ridge meta-learner
4. **Evaluation:** RÂ², RMSE, MAE on test set
5. **Model Persistence:** Save using joblib

---

## ğŸ“Š Business Impact

### Current Performance
- **Prediction Accuracy:** 72.6% of fare variance explained
- **Average Error:** $1.37 per ride
- **Typical $10 Ride:** Predicted between $8.60 - $11.40

### Potential Improvements
With additional data (traffic, weather, surge pricing):
- **Expected Accuracy:** 80-85% RÂ²
- **Expected Error:** $0.80-$1.20 per ride

---

## ğŸ¤ Contributing

This project follows industry best practices:

1. **Code Style:** Black formatter (100 char line length)
2. **Linting:** flake8 with project-specific rules
3. **Testing:** pytest with comprehensive test coverage
4. **Security:** Bandit for vulnerability scanning
5. **CI/CD:** Automated quality checks with `make ci`

---

## ğŸ“ License

This project is created for educational purposes.

---

## ğŸ‘¨â€ğŸ’» Author

**Yassine Maazaoui**
- Machine Learning Student
- Focus: Data Science & Predictive Analytics

---

## ğŸ™ Acknowledgments

- Dataset: Uber Ride Data (44,377 trips)
- Libraries: scikit-learn, XGBoost, LightGBM, CatBoost
- Tools: Python, Makefile, pytest, Black, flake8

---

## ğŸ“… Project Timeline

- **Phase 1:** Model Development & Training âœ…
- **Phase 2:** Infrastructure & Automation âœ…
- **Phase 3:** Graphical Interface ğŸ”œ
- **Phase 4:** Deployment ğŸ”œ

---

## ğŸ“ Support

For questions or issues:
1. Check the documentation above
2. Run `make help` for available commands
3. Review test results with `make test`
4. Run full quality check with `make ci`

---

**Last Updated:** December 12, 2025
**Version:** 1.0.0

